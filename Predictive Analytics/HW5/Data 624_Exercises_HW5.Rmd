---
title: "Data 624_Exercise 8.8_HW5"
author: "Jiaxin Zheng"
date: "2025-03-31"
output:
  html_document: default
  pdf_document:     
    latex_engine: xelatex
---

# 8.8 Exercises:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(fpp3)
library(dplyr)
```
## 1. Consider the the number of pigs slaughtered in Victoria, available in the aus_livestock dataset.

- a. Use the ETS() function to estimate the equivalent model for simple exponential smoothing. Find the optimal values of  
α and ℓ0, and generate forecasts for the next four months. 

- alpha = 0.3221247; initial states = 100646.6

```{r}
?aus_livestock
```

```{r}
head(aus_livestock)
```

```{r}
vic_pigs <- aus_livestock %>%
  filter(State == "Victoria", Animal == "Pigs")
vic_pigs
```

```{r}
autoplot(vic_pigs)
```

```{r}
# fit model
fit <- vic_pigs %>% 
  model(ETS(Count ~ error("A") + trend("N") + season("N")))

report(fit)
```

```{r}
fc <- fit %>% forecast(h = "4 months")
fc %>% 
  autoplot(vic_pigs)+
  labs(title="Four Month Forecast for Victorian Pigs")
```

- b. Compute a 95% prediction interval for the first forecast using ^y±1.96s where s is the standard deviation of the residuals. Compare your interval with the interval produced by R.

```{r}
# Get residuals standard deviation
s <- sd(residuals(fit)$.resid)

# Get first forecast value
first_forecast <- fc$.mean[1]

# Calculate manual prediction interval
lower <- first_forecast - 1.96 * s
upper <- first_forecast + 1.96 * s

paste0("lower:", lower)
paste0("upper:", upper)
```

```{r}
# R's interval
fc |>
    head(1) |>
    hilo() |>
    pull(`95%`)
```


## 5.Data set global_economy contains the annual Exports from many countries. Select one country to analyse.

- a.Plot the Exports series and discuss the main features of the data.
```{r}
head(global_economy)
```

```{r}
US <- global_economy %>% 
  filter(Country == "United States")

US %>% 
  autoplot(Exports) +
  labs(title = "United States Exports")
```



- b.Use an ETS(A,N,N) model to forecast the series, and plot the forecasts.
```{r}
fit <- US %>%
  filter(!is.na(Exports)) %>% 
  model(ETS(Exports ~ error("A") + trend("N")+ season("N")))

fc <- fit %>% forecast(h = 10)

autoplot(fc, US) +
  labs(title = "United States Exports 10 Year Forecast")
```


- c.Compute the RMSE values for the training data.
- RMSE number is 0.6270672.	

```{r}
accuracy(fit)
```


- d.Compare the results to those from an ETS(A,A,N) model. (Remember that the trended model is using one more parameter than the simpler model.) Discuss the merits of the two forecasting methods for this data set.

- The AAN have RMSE number 0.6270672.
```{r}
fit_2 <- US %>%
  filter(!is.na(Exports)) %>% 
  model(ANN= ETS(Exports ~ error("A") + trend("N")+ season("N")),
        AAN = ETS(Exports ~ error("A") + trend("A")+ season("N")))

fc_2 <- fit_2 %>% forecast(h = 10)

autoplot(fc_2, US, level = NULL) +
  labs(title = "ANN vs. AAN United States Exports 10 Year Forecast")
```

```{r}
accuracy(fit_2)
```


- e.Compare the forecasts from both methods. Which do you think is best?

- The AAN method seems better, the RMSE number is lower than ANN.


- f.Calculate a 95% prediction interval for the first forecast for each model, using the RMSE values and assuming normal errors. Compare your intervals with those produced using R.

```{r}
# Get residuals standard deviation
s_2 <- sd(residuals(fit_2)$.resid)

# Get first forecast value
first_forecast_2 <- fc_2$.mean[1]

# Calculate manual prediction interval
lower_2 <- first_forecast_2 - 1.96 * s
upper_2 <- first_forecast_2 + 1.96 * s

paste0("lower:", lower)
paste0("upper:", upper)
```

```{r}
# R's interval
fc_2 |>
    head(1) |>
    hilo() |>
    pull(`95%`)
```
`

## 6. Forecast the Chinese GDP from the global_economy data set using an ETS model. Experiment with the various options in the ETS() function to see how much the forecasts change with damped trend, or with a Box-Cox transformation. Try to develop an intuition of what each is doing to the forecasts.

- Hint, use a relatively large value of h when forecasting, so you can clearly see the differences between the various options when plotting the forecasts.

```{r}
china_gdp <- global_economy %>% 
  filter(Country == "China")

china_gdp %>% 
  autoplot(GDP) +
  labs(title = "GDP for China")
```

```{r}
# Compute optimal Box-Cox lambda
lambda <- china_gdp %>%
  features(GDP, features = guerrero) %>%
  pull(lambda_guerrero)

# Fit three models
models <- china_gdp %>%
  model(
    basic_ETS = ETS(GDP),
    AAdN = ETS(GDP ~ error("A") + trend("Ad") + season("N")),
    ANN = ETS(GDP ~ error("A") + trend("A") + season("N")),
    boxcox_ETS = ETS(box_cox(GDP, lambda) ~ error("A") + trend("A") + season("N"))
  )

# Forecast 20 years
forecasts <- models %>%
  forecast(h = 20)

forecasts %>%
  autoplot(china_gdp, level = NULL) +
  labs(title = "Comparison of ETS Forecasts for Chinese GDP",
       y = "GDP",
       x = "Year")
```


## 7.Find an ETS model for the Gas data from aus_production and forecast the next few years. Why is multiplicative seasonality necessary here? Experiment with making the trend damped. Does it improve the forecasts?

- Looking at the model fits, the Multiplicative seasonality is a bit better than others because the RMSE is low.
```{r}
gas <- aus_production %>%
  select(Quarter, Gas) %>%
  filter(!is.na(Gas))

gas %>%
  autoplot(Gas) +
  labs(title = "Australian Gas Production", y = "Gas Production")

```

```{r}
# Fit ETS models
gas_models <- gas %>%
  model(
    AAA = ETS(Gas ~ error("A") + trend("A") + season("A")),
    MAM = ETS(Gas ~ error("M") + trend("A") + season("M")),
    MAdM = ETS(Gas ~ error("M") + trend("Ad") + season("M"))
  )

# Forecast 5 years 
gas_forecasts <- gas_models %>%
  forecast(h = "5 years")

gas_forecasts %>%
  autoplot(gas, level = NULL) +
  labs(title = "Gas Forecasts Using ETS Models",
       y = "Gas Production")
```


```{r}
accuracy(gas_models)
```


## 8.Recall your retail time series data (from Exercise 7 in Section 2.10).

- a.Why is multiplicative seasonality necessary for this series?
- There is an exhibited season pattern and multiplicative seasonality is needed due to the increase in the variance of the seasonality overtime.
```{r}
set.seed(12345678)
myseries <- aus_retail |>
  filter(`Series ID` == sample(aus_retail$`Series ID`,1))
```

```{r}
myseries %>% 
  autoplot(Turnover) +
  labs(title = 'Australian Retail Turnover')
```


- b.Apply Holt-Winters’ multiplicative method to the data. Experiment with making the trend damped.
```{r}
fit_myseries <- myseries|>
  model("multiplicative" = ETS(Turnover ~ error("M") + trend("A") + season("M")),
        "damped multiplicative" = ETS(Turnover ~ error("M") + trend("Ad") + season("M")))

fc_myseries <- fit_myseries |>
  forecast(h = "3 years")

fc_myseries |>
  autoplot(myseries, level=NULL) +
  labs(title = "Australian Retail Turnover Forecasts: Next 3 Years")
```


- c.Compare the RMSE of the one-step forecasts from the two methods. Which do you prefer?
- Compare the RMSE here is no much different. But the model damped multiplicative is slightly better then multiplicative. 
```{r}
accuracy(fit_myseries)
```


- d.Check that the residuals from the best method look like white noise.
- It looks like white noise. 
- In residuals over time plot, there is no strong patterns, no clear tends.
- In ACF plot: Most bars are within the blue dash lines, only two minor lags.
- In histogram plot: Looks like normally distributed, even the plot slight skew, but still good.
```{r}
best_mod <- myseries %>%
  model(ETS(Turnover ~ error("M") + trend("Ad") + season("M")))

best_mod %>%
  gg_tsresiduals()
```


- e.Now find the test set RMSE, while training the model to the end of 2010. Can you beat the seasonal naïve approach from Exercise 7 in Section 5.11?
- Holt-Winters method is better. Holt-Winters method get RMSE 0.5185084, and Snaive get RMSE 1.2137305.

```{r}
myseries_train <- myseries %>% 
  filter(year(Month) < 2011)
```

```{r}
my_fit_3 <- myseries_train %>% 
  model(
    hw = ETS(Turnover ~ error('M') + trend('Ad') + season('M')),
    Snaive = SNAIVE(Turnover)
  )

my_fc_3 <- my_fit_3 %>% 
  forecast(h = '10 year')

my_fc_3 %>% 
  autoplot(myseries, level = NULL) +
  ggtitle('SNAIVE vs Holt-Winters method for forecasting 10 years of turnover in retail')
```

```{r}
accuracy(my_fit_3)
```


## 9.For the same retail data, try an STL decomposition applied to the Box-Cox transformed series, followed by ETS on the seasonally adjusted data. How does that compare with your best previous forecasts on the test set?
- After STL decomposition applied to the Box-Cox transformed series, the RMSE number is 0.6155067. It is larger than my best previous forecasts, it means my best previous forecasts is better.

```{r}
#find the best lambda:
lambda <- myseries %>% 
  features(Turnover, features = guerrero) %>% 
  pull(lambda_guerrero)
#box cox to STL decomposition (chapter 3.6)
stl_model <- myseries %>%
  model(
    STL = STL(box_cox(Turnover, lambda) ~ trend() + season(window = "periodic"))
  ) %>% 
  components()
```

```{r}
#Apply ETS methods to the transformed data
ets_4<- myseries %>% 
  model(
    MAdA = ETS(Turnover ~ error('M') + trend('Ad')+season('M'))
  )

#forecast for 10 years
fc_4<- ets_4 %>% 
  forecast(h = '10 year')

fc_4 %>% 
  autoplot(myseries, level = NULL)+
  labs(title='seasonally adjusted with MAdM forecast')
```


```{r}
accuracy(ets_4)
```



